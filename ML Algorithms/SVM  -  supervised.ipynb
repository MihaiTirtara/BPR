{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##imports\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Needed CSV's\n",
    "trainingData = pd.read_csv(\"train.csv\", index_col=0) \n",
    "testingData  = pd.read_csv(\"test.csv\", index_col=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##batch size (started with a small no. to train the algorithm on)\n",
    "batch_size = 320000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##vectorizing the data\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(trainingData[:batch_size]['OCR text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = trainingData[:batch_size][\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1023804)\t0.17356085231708732\n",
      "  (0, 3902906)\t0.11006352215199676\n",
      "  (0, 1994521)\t0.17368667202763452\n",
      "  (0, 1105205)\t0.10576162854433116\n",
      "  (0, 486789)\t0.2621773100694327\n",
      "  (0, 613354)\t0.2228816039914777\n",
      "  (0, 615186)\t0.20749094914032148\n",
      "  (0, 3269928)\t0.12909278246115696\n",
      "  (0, 1565801)\t0.10914941928698993\n",
      "  (0, 2774797)\t0.0990143902998192\n",
      "  (0, 3522610)\t0.10883672516232283\n",
      "  (0, 2869639)\t0.09994235132014762\n",
      "  (0, 3269883)\t0.22967632373744243\n",
      "  (0, 1154145)\t0.1358293341451583\n",
      "  (0, 640366)\t0.16160764306247738\n",
      "  (0, 3387834)\t0.07002938197734061\n",
      "  (0, 1271309)\t0.08842233560437013\n",
      "  (0, 1111183)\t0.11582977767520121\n",
      "  (0, 3280571)\t0.24496235065522273\n",
      "  (0, 346899)\t0.2119889565398721\n",
      "  (0, 3387681)\t0.08155898259578934\n",
      "  (0, 2918596)\t0.21840229149025575\n",
      "  (0, 785441)\t0.2460772720436303\n",
      "  (0, 362384)\t0.22574311148663473\n",
      "  (0, 2169322)\t0.2748617352756527\n",
      "  :\t:\n",
      "  (319999, 1347754)\t0.3541882361429565\n",
      "  (319999, 2597553)\t0.3541882361429565\n",
      "  (319999, 378591)\t0.2831840859748654\n",
      "  (319999, 2302984)\t0.2067974356654456\n",
      "  (319999, 2088291)\t0.2711304173153051\n",
      "  (319999, 3218725)\t0.2812346092324707\n",
      "  (319999, 3956097)\t0.20760813272067935\n",
      "  (319999, 2087511)\t0.21320953220102493\n",
      "  (319999, 1679785)\t0.21633547953238477\n",
      "  (319999, 3935682)\t0.16295176622523533\n",
      "  (319999, 1605668)\t0.18544994920128394\n",
      "  (319999, 710318)\t0.16844544253977958\n",
      "  (319999, 1569350)\t0.18421405796972004\n",
      "  (319999, 505415)\t0.134717876492383\n",
      "  (319999, 2076398)\t0.18764296651526743\n",
      "  (319999, 1183575)\t0.13764818989055105\n",
      "  (319999, 1507990)\t0.17204746369773044\n",
      "  (319999, 1232892)\t0.10145192297882559\n",
      "  (319999, 1666215)\t0.13265802949166858\n",
      "  (319999, 2521103)\t0.07994678356596956\n",
      "  (319999, 1501016)\t0.07837627825524188\n",
      "  (319999, 2607641)\t0.09854631338245302\n",
      "  (319999, 2062627)\t0.15150298459399858\n",
      "  (319999, 1292268)\t0.18533779666341216\n",
      "  (319999, 3337010)\t0.07468933135107854\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Creating pipelines for SVM\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "svm_pipeline = Pipeline([\n",
    "    ('svm', SGDClassifier(max_iter=320000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l2 .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l2, score=0.723, total=  24.5s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l2 .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l2, score=0.724, total=  24.0s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l2 .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l2, score=0.725, total=  23.8s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l2 .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l2, score=0.725, total=  24.3s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l2 .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l2, score=0.726, total=  23.5s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l1 .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l1, score=0.557, total=  47.3s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l1 .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l1, score=0.562, total=  47.4s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l1 .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l1, score=0.555, total=  48.7s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l1 .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l1, score=0.566, total=  50.5s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l1 .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=l1, score=0.554, total=  49.5s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=none ...........\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=none, score=0.744, total=  31.5s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=none ...........\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=none, score=0.743, total=  30.7s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=none ...........\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=none, score=0.746, total=  30.5s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=none ...........\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=none, score=0.747, total=  30.4s\n",
      "[CV] svm__alpha=0.0001, svm__loss=hinge, svm__penalty=none ...........\n",
      "[CV]  svm__alpha=0.0001, svm__loss=hinge, svm__penalty=none, score=0.747, total=  31.3s\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=l2 ...............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=l2, score=0.664, total=  29.2s\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=l2 ...............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=l2, score=0.666, total=  29.3s\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=l2 ...............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=l2, score=0.668, total=  28.9s\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=l2 ...............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=l2, score=0.666, total=  28.6s\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=l2 ...............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=l2, score=0.667, total=  29.7s\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=l1 ...............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=l1, score=0.581, total= 1.1min\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=l1 ...............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=l1, score=0.582, total= 1.1min\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=l1 ...............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=l1, score=0.585, total= 1.1min\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=l1 ...............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=l1, score=0.581, total= 1.1min\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=l1 ...............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=l1, score=0.585, total= 1.1min\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=none .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=none, score=0.730, total=  35.6s\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=none .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=none, score=0.729, total=  37.6s\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=none .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=none, score=0.732, total=  36.6s\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=none .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=none, score=0.731, total=  36.7s\n",
      "[CV] svm__alpha=0.0001, svm__loss=log, svm__penalty=none .............\n",
      "[CV]  svm__alpha=0.0001, svm__loss=log, svm__penalty=none, score=0.731, total=  36.7s\n",
      "[CV] svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l2 .....\n",
      "[CV]  svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l2, score=0.735, total= 1.2min\n",
      "[CV] svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l2 .....\n",
      "[CV]  svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l2, score=0.744, total= 1.2min\n",
      "[CV] svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l2 .....\n",
      "[CV]  svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l2, score=0.736, total= 1.0min\n",
      "[CV] svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l2 .....\n",
      "[CV]  svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l2, score=0.742, total= 2.7min\n",
      "[CV] svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l2 .....\n",
      "[CV]  svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l2, score=0.736, total= 1.0min\n",
      "[CV] svm__alpha=0.0001, svm__loss=squared_hinge, svm__penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   48.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  3.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  4.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  5.2min remaining:    0.0s\n"
     ]
    }
   ],
   "source": [
    "##Listing the testing tuning parameters\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_params = {    \n",
    "    \"svm__loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"svm__alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"svm__penalty\" : [\"l2\", \"l1\", \"none\"],\n",
    "}\n",
    "clf = GridSearchCV(svm_pipeline, grid_params,verbose=10)\n",
    "clf.fit(X, y)\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(\"Best Params: \", clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Fiting the data and training it - modify tuning parameters here based on the GridsearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(alpha=0.0001, loss='hinge', penalty='none')\n",
    "\n",
    "clf.fit(X, y)\n",
    "joblib.dump(clf, 'svm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": [
    "##Testing data based on the fitted model\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Prediction and accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "documents1 = testingData[:][\"OCR text\"]\n",
    "y_true = testingData[:]['Label']\n",
    "input = vectorizer.transform(documents1)\n",
    "prediction1= clf.predict(input)\n",
    "\n",
    "dataframe = pd.DataFrame(list(y_true),prediction1)\n",
    "index = 0\n",
    "count = 0\n",
    "for i in tqdm(list(y_true)):\n",
    "    if i == prediction1[index]:\n",
    "        count += 1\n",
    "    index+=1\n",
    "    \n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(list(y_true),prediction1))\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "document_classification_resub.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PyCharm (BPR)",
   "language": "python",
   "name": "pycharm-e03079fb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}